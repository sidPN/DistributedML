# DistributedML
To understand the concepts of SSP and BSP in distributed, data-parallel ML.
Using Parameter Server(PS) as an abstraction for distribute, data-parallel ML, implemented Gibbs Sampling for LDA(Latent Dirichlet Allocation) using a PS - JBosen, on the 20Newsgroup dataset.
