# DistributedML
Assignment as a part of CMU course (10-605) to understand the concepts of Stale Synchronous Parallel(SSP) and Bulk Synchronous Parallel(BSP) in distributed, data-parallel ML.
Using Parameter Server(PS) as an abstraction for distribute, data-parallel ML, implemented Gibbs Sampling for LDA(Latent Dirichlet Allocation) using a PS - JBosen, on the 20Newsgroup dataset.
